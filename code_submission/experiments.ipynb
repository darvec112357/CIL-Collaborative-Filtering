{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "from time import time\n",
    " \n",
    "from train_test import get_train_test, convert_df_to_matrix, _read_df_in_format\n",
    "\n",
    "# Surprise package for dataloading and evaluation\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import accuracy as acc    \n",
    "\n",
    "# Baseline 1: Averaging\n",
    "from averaging import UserAverage, ItemAverage, UserItemAverage\n",
    "\n",
    "# Baseline 2: Iterative SVD \n",
    "from svdals import normalize, ALS\n",
    "\n",
    "# Baseline 3: Neural Collaborative Filtering\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "from ncf import CFDataset, GMF, MLP, NeuMF\n",
    "from ncf import nn_train, nn_predict\n",
    "\n",
    "# BFM + Adaptions \n",
    "from bfm import run_bfm, generate_clusters, create_augmented_dataset, run_bfm_augmented "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluationn\n",
    "def print_scores(y_true, y_pred, name):\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    print(f\"Method: {name}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: These experiments are conducted on a custom train-test split for comparison. To generate the final results for submission, the data will just be the full training data set instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data/'\n",
    "train_df, test_df = get_train_test(os.path.join(data_folder, 'data_train.csv'), split_num=0)\n",
    "train_matrix = convert_df_to_matrix(train_df)\n",
    "\n",
    "y_true = test_df['Prediction'].to_numpy()\n",
    "\n",
    "train_df_full = _read_df_in_format(os.path.join(data_folder, 'data_train.csv'))\n",
    "train_matrix_full = convert_df_to_matrix(train_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For usage with Surprise package\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "train_data = Dataset.load_from_df(train_df, reader)\n",
    "test_data = Dataset.load_from_df(test_df, reader)\n",
    "\n",
    "trainset = train_data.build_full_trainset()\n",
    "testset = test_data.build_full_trainset().build_testset()\n",
    "anti_trainset = trainset.build_anti_testset()\n",
    "\n",
    "# Full trainset\n",
    "train_data_full = Dataset.load_from_df(train_df_full, reader)\n",
    "trainset_full = train_data_full.build_full_trainset()\n",
    "anti_trainset_full = trainset_full.build_anti_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 1: Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is performed primarily as a sanity check for future methods; it represents the average across the various dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: UserAverage, RMSE: 1.0949, MAE: 0.9009, Time: 1.82\n",
      "Method: ItemAverage, RMSE: 1.0309, MAE: 0.8398, Time: 1.58\n",
      "Method: UserItemAverage, RMSE: 1.0314, MAE: 0.8482, Time: 1.59\n"
     ]
    }
   ],
   "source": [
    "methods = [UserAverage, ItemAverage, UserItemAverage]\n",
    "\n",
    "for method in methods:\n",
    "    start_time = time()\n",
    "    algo = method()\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    print(f\"Method: {method.__name__}, RMSE: {acc.rmse(predictions, False):.4f}, MAE: {acc.mae(predictions, False):.4f}, Time: {time() - start_time:.2f}\", end = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 2: SVD + ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method first applies SVD iteratively with shrinkage as an initialization for the U and V matrices. After which, the decomposition is limited to $k$ ranks and Alternating Least Squares is performed to optimize the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix_na = train_matrix.copy()\n",
    "train_matrix_na[train_matrix_na == 0] = np.nan\n",
    "A, mean, std = normalize(train_matrix_na)\n",
    "\n",
    "A = A.to_numpy()\n",
    "A[np.isnan(A)] = 0\n",
    "mask_A = A != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing IterSVD\n",
      "IterSVD completelete\n",
      "Iteration 1\t\tError after solving for U matrix: 0.88878528090379\t\tError after solving for V matrix: 0.8699788788828307\n",
      "Iteration 2\t\tError after solving for U matrix: 0.8694005409783845\t\tError after solving for V matrix: 0.8636261330729882\n",
      "Iteration 3\t\tError after solving for U matrix: 0.8646307420528284\t\tError after solving for V matrix: 0.8616478322078692\n",
      "Iteration 4\t\tError after solving for U matrix: 0.8625725718395331\t\tError after solving for V matrix: 0.8607290666194622\n",
      "Iteration 5\t\tError after solving for U matrix: 0.8614763785422687\t\tError after solving for V matrix: 0.8602207445063061\n",
      "Iteration 6\t\tError after solving for U matrix: 0.8608178563885811\t\tError after solving for V matrix: 0.8599073772503655\n",
      "Iteration 7\t\tError after solving for U matrix: 0.8603893940900001\t\tError after solving for V matrix: 0.8596993060114979\n",
      "Iteration 8\t\tError after solving for U matrix: 0.8600941682702217\t\tError after solving for V matrix: 0.8595534570369412\n",
      "Iteration 9\t\tError after solving for U matrix: 0.8598817238572822\t\tError after solving for V matrix: 0.8594469119058854\n",
      "Iteration 10\t\tError after solving for U matrix: 0.8597235439784068\t\tError after solving for V matrix: 0.8593665033841708\n",
      "Iteration 11\t\tError after solving for U matrix: 0.8596024740166613\t\tError after solving for V matrix: 0.8593042000245612\n",
      "Iteration 12\t\tError after solving for U matrix: 0.8595076703944887\t\tError after solving for V matrix: 0.8592548624297754\n",
      "Iteration 13\t\tError after solving for U matrix: 0.8594319963068745\t\tError after solving for V matrix: 0.8592150701646631\n",
      "Iteration 14\t\tError after solving for U matrix: 0.8593705939784179\t\tError after solving for V matrix: 0.8591824710088254\n",
      "Iteration 15\t\tError after solving for U matrix: 0.85932006138458\t\tError after solving for V matrix: 0.8591554017958126\n",
      "Iteration 16\t\tError after solving for U matrix: 0.8592779570101331\t\tError after solving for V matrix: 0.8591326581661587\n",
      "Iteration 17\t\tError after solving for U matrix: 0.8592424910178388\t\tError after solving for V matrix: 0.859113349725909\n",
      "Iteration 18\t\tError after solving for U matrix: 0.8592123265898406\t\tError after solving for V matrix: 0.8590968061102139\n",
      "Iteration 19\t\tError after solving for U matrix: 0.8591864486310581\t\tError after solving for V matrix: 0.859082514417415\n",
      "Iteration 20\t\tError after solving for U matrix: 0.859164074898457\t\tError after solving for V matrix: 0.8590700765479098\n",
      "Time: 615.27\n"
     ]
    }
   ],
   "source": [
    "als = ALS()\n",
    "start = time()\n",
    "U, V = als.ALS(A, mask_A, k=3, shrinkage=30, lambd=0.1, n_iter_svd=5, n_iter_als=20)\n",
    "end = time(); print(f\"Time: {end - start:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = als.predict(U, V, mean, std)\n",
    "row_ids = test_df.row.to_numpy() - 1\n",
    "col_ids = test_df.col.to_numpy() - 1\n",
    "test_preds = predictions[row_ids, col_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Iterative SVD with ALS, RMSE: 0.9921, MAE: 0.7896\n"
     ]
    }
   ],
   "source": [
    "print_scores(y_true, test_preds, \"Iterative SVD with ALS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 3: NCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses Neural Collaborative Filtering. To improve the process, a Generalzied Factorization Machine and a Multi-Layer Perceptron are first trained separately, then used as pre-trained weights for the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CFDataset(train_df.values)\n",
    "train_loader = DataLoader(trainset, batch_size=256, shuffle=True)\n",
    "\n",
    "testset = CFDataset(test_df.values)\n",
    "test_loader = DataLoader(testset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 32\n",
    "hidden_dims = [64, 32]\n",
    "num_users, num_items = train_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Batch: 3600, Loss: 1.038\r"
     ]
    }
   ],
   "source": [
    "gmf = GMF(latent_dim=latent_dim, num_users=num_users, num_items=num_items)\n",
    "loss_function = MSELoss()\n",
    "optimizer = Adam(gmf.parameters(), lr=0.001)\n",
    "\n",
    "model = nn_train(gmf, train_loader, loss_function, optimizer)\n",
    "torch.save(model.state_dict(), 'models/gmf.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: GMF Only, RMSE: 1.0822, MAE: 0.8795\n"
     ]
    }
   ],
   "source": [
    "y_pred_gmf = nn_predict(gmf, test_loader)\n",
    "y_pred_gmf = np.clip(y_pred_gmf, 1, 5)\n",
    "print_scores(y_true, y_pred_gmf, \"GMF Only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Batch: 3600, Loss: 1.024\r"
     ]
    }
   ],
   "source": [
    "mlp = MLP(latent_dim=latent_dim, num_users=num_users, num_items=num_items, hidden_layers=hidden_dims)\n",
    "loss_function = MSELoss()\n",
    "optimizer = Adam(mlp.parameters(), lr=0.001)\n",
    "\n",
    "model = nn_train(mlp, train_loader, loss_function, optimizer)\n",
    "torch.save(model.state_dict(), 'models/mlp.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: MLP Only, RMSE: 1.0029, MAE: 0.8105\n"
     ]
    }
   ],
   "source": [
    "y_pred_mlp = nn_predict(mlp, test_loader)\n",
    "y_pred_mlp = np.clip(y_pred_mlp, 1, 5)\n",
    "print_scores(y_true, y_pred_mlp, \"MLP Only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuMF with pre-training\n",
    "This makes use of the previously learnt GMF and MLP as initializations for the NeuMF model. The models are weighted by an $\\alpha$ value where $\\alpha=0$ fully uses the MLP model, while $\\alpha=1$ fully uses the GMF model.  \n",
    "After tuning for various $\\alpha$ values, an appropriate value was selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_pretrained = NeuMF(latent_dim=latent_dim, num_users=num_users, num_items=num_items, hidden_layers=hidden_dims, pretrained=True, alpha=0.05)\n",
    "neumf_dict = neumf_pretrained.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gmf_state_dict = torch.load('models/gmf.pth')\n",
    "mlp_state_dict = torch.load('models/mlp.pth')\n",
    "\n",
    "pretrained_dict_gmf = {k: v for k, v in gmf_state_dict.items() if k in neumf_dict}\n",
    "pretrained_dict_mlp = {k: v for k, v in mlp_state_dict.items() if k in neumf_dict}\n",
    "\n",
    "neumf_dict.update(pretrained_dict_gmf)\n",
    "neumf_dict.update(pretrained_dict_mlp)\n",
    "neumf_pretrained.load_state_dict(neumf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Batch: 3600, Loss: 0.997\r"
     ]
    }
   ],
   "source": [
    "loss_function = MSELoss()\n",
    "optimizer = SGD(neumf_pretrained.parameters(), lr=0.001)\n",
    "\n",
    "model = nn_train(neumf_pretrained, train_loader, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: NeuMF Pretrained, RMSE: 1.0041, MAE: 0.8092\n"
     ]
    }
   ],
   "source": [
    "y_pred_neumf_pretrained = nn_predict(neumf_pretrained, test_loader)\n",
    "y_pred_neumf_pretrained = np.clip(y_pred_neumf_pretrained, 1, 5)\n",
    "print_scores(y_true, y_pred_neumf_pretrained, \"NeuMF Pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Factorization Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "This only uses the individual ratings, without utilising any other knowledge about user/item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "w0 = 0.12, cutpoint = ['-1.983', '-1.237', '-0.263', '0.613'] : 100%|██████████| 200/200 [02:43<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred_bfm, fm = run_bfm(train_df, test_df, rank=10, fm_kind='classifier') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: BFM Baseline, RMSE: 0.9777, MAE: 0.7809\n"
     ]
    }
   ],
   "source": [
    "print_scores(y_true, y_pred_bfm, \"BFM Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusing with KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing preliminary experiments with various methods, we noticed that K-Nearest-Neighbours worked relatively well despite its simplicity. Therefore, we wanted to supplement the BFM with KNN predictions.  \n",
    "Using KNN to train the model, we generated predictions for all datapoints within rating matrix and their corresponding clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "antitrain_df = generate_clusters(trainset, anti_trainset, n_clusters=30)\n",
    "# antitrain_df.to_csv('models/knn_clusters.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 2.49 w0 = 2.58 : 100%|██████████| 200/200 [04:47<00:00,  1.44s/it]\n",
      "alpha = 2.49 w0 = 2.58 : 100%|██████████| 200/200 [05:52<00:00,  1.76s/it]\n",
      "alpha = 2.49 w0 = 2.58 : 100%|██████████| 200/200 [05:14<00:00,  1.57s/it]\n",
      "alpha = 2.49 w0 = 2.58 : 100%|██████████| 200/200 [05:17<00:00,  1.59s/it]\n",
      "alpha = 2.49 w0 = 2.58 : 100%|██████████| 200/200 [07:21<00:00,  2.21s/it]\n"
     ]
    }
   ],
   "source": [
    "y_pred_ensemble = run_bfm_augmented(train_df, antitrain_df, test_df, n_samples_per_cluster=50000, rank=10, seed_lst=[1, 42, 66, 88, 420])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: BFM with KNN Preds, RMSE: 0.9840, MAE: 0.7808\n"
     ]
    }
   ],
   "source": [
    "print_scores(y_true, y_pred_ensemble['Prediction_avg'], \"BFM with KNN Preds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
